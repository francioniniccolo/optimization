{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set : [[ 8.7   0.69  0.31 ...  3.48  0.74 11.6 ]\n",
      " [ 6.1   0.21  0.4  ...  3.25  0.59 11.9 ]\n",
      " [10.9   0.39  0.47 ...  3.3   0.75  9.8 ]\n",
      " ...\n",
      " [ 7.2   0.62  0.06 ...  3.51  0.54  9.5 ]\n",
      " [ 7.9   0.2   0.35 ...  3.32  0.8  11.9 ]\n",
      " [ 5.8   0.29  0.26 ...  3.39  0.54 13.5 ]] , shape: (1279, 11)\n",
      "Test set : [[ 7.7    0.56   0.08  ...  3.24   0.66   9.6  ]\n",
      " [ 7.8    0.5    0.17  ...  3.39   0.48   9.5  ]\n",
      " [10.7    0.67   0.22  ...  3.28   0.98   9.9  ]\n",
      " ...\n",
      " [ 8.3    0.6    0.25  ...  3.15   0.53   9.8  ]\n",
      " [ 8.8    0.27   0.39  ...  3.15   0.69  11.2  ]\n",
      " [ 9.1    0.765  0.04  ...  3.29   0.54   9.7  ]] , shape: (320, 11)\n"
     ]
    }
   ],
   "source": [
    "features_train = train_data.copy()\n",
    "labels_train = features_train.pop('quality')\n",
    "features_train = np.array(features_train)\n",
    "print(\"Train set : {train_set} , shape: {size}\".format(train_set=features_train,size=features_train.shape))\n",
    "\n",
    "\n",
    "features_test = test_data.copy()\n",
    "labels_test = features_test.pop('quality')\n",
    "features_test = np.array(features_test)\n",
    "print(\"Test set : {test_set} , shape: {size}\".format(test_set=features_test,size=features_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niccolo/python-projects/optimization/env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 15.9528 - mae: 3.4124 - val_loss: 2.6577 - val_mae: 1.2187\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.9161 - mae: 1.2703 - val_loss: 2.2079 - val_mae: 1.0635\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.4696 - mae: 1.1728 - val_loss: 1.5259 - val_mae: 0.8889\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9951 - mae: 1.0376 - val_loss: 1.3812 - val_mae: 0.8535\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8177 - mae: 0.9859 - val_loss: 1.3080 - val_mae: 0.8355\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6006 - mae: 0.8954 - val_loss: 0.9919 - val_mae: 0.6911\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4483 - mae: 0.8634 - val_loss: 0.9771 - val_mae: 0.6706\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3680 - mae: 0.8301 - val_loss: 0.9884 - val_mae: 0.6662\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3470 - mae: 0.8316 - val_loss: 0.7982 - val_mae: 0.5824\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2008 - mae: 0.7738 - val_loss: 1.4174 - val_mae: 0.9363\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1616 - mae: 0.7479 - val_loss: 0.8033 - val_mae: 0.5877\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1349 - mae: 0.7544 - val_loss: 0.7330 - val_mae: 0.5631\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0996 - mae: 0.7477 - val_loss: 0.7102 - val_mae: 0.5518\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0610 - mae: 0.7172 - val_loss: 1.2457 - val_mae: 0.8522\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1297 - mae: 0.7522 - val_loss: 1.2575 - val_mae: 0.8648\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9992 - mae: 0.7059 - val_loss: 0.8231 - val_mae: 0.6059\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0655 - mae: 0.7252 - val_loss: 0.7327 - val_mae: 0.5852\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9243 - mae: 0.6764 - val_loss: 0.7060 - val_mae: 0.5731\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0540 - mae: 0.7236 - val_loss: 1.0336 - val_mae: 0.7657\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0343 - mae: 0.7147 - val_loss: 0.8302 - val_mae: 0.6233\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9849 - mae: 0.7128 - val_loss: 1.0694 - val_mae: 0.7765\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9347 - mae: 0.6860 - val_loss: 0.6526 - val_mae: 0.5407\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8662 - mae: 0.6475 - val_loss: 0.6764 - val_mae: 0.5610\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8269 - mae: 0.6286 - val_loss: 0.8516 - val_mae: 0.6406\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8154 - mae: 0.6221 - val_loss: 0.6897 - val_mae: 0.5612\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8986 - mae: 0.6684 - val_loss: 0.6548 - val_mae: 0.5247\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8461 - mae: 0.6348 - val_loss: 0.6349 - val_mae: 0.5276\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.8478 - mae: 0.6449 - val_loss: 0.7592 - val_mae: 0.5830\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7895 - mae: 0.6123 - val_loss: 0.6124 - val_mae: 0.5056\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8368 - mae: 0.6516 - val_loss: 0.7036 - val_mae: 0.5891\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8144 - mae: 0.6440 - val_loss: 0.6829 - val_mae: 0.5631\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7293 - mae: 0.5877 - val_loss: 0.7353 - val_mae: 0.5884\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7797 - mae: 0.6328 - val_loss: 0.6893 - val_mae: 0.5646\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7701 - mae: 0.6206 - val_loss: 0.6748 - val_mae: 0.5581\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7248 - mae: 0.5871 - val_loss: 0.6709 - val_mae: 0.5708\n",
      "Epoch 36/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7964 - mae: 0.6294 - val_loss: 0.6268 - val_mae: 0.5310\n",
      "Epoch 37/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6932 - mae: 0.5726 - val_loss: 0.8299 - val_mae: 0.6431\n",
      "Epoch 38/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7707 - mae: 0.6237 - val_loss: 0.6913 - val_mae: 0.5767\n",
      "Epoch 39/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7003 - mae: 0.5898 - val_loss: 0.6131 - val_mae: 0.5351\n",
      "Epoch 40/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6475 - mae: 0.5559 - val_loss: 0.5825 - val_mae: 0.5051\n",
      "Epoch 41/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6858 - mae: 0.5708 - val_loss: 0.6442 - val_mae: 0.5507\n",
      "Epoch 42/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7299 - mae: 0.5930 - val_loss: 0.6044 - val_mae: 0.5405\n",
      "Epoch 43/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7088 - mae: 0.5842 - val_loss: 0.5911 - val_mae: 0.5264\n",
      "Epoch 44/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6262 - mae: 0.5571 - val_loss: 0.6595 - val_mae: 0.5500\n",
      "Epoch 45/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6582 - mae: 0.5662 - val_loss: 0.6942 - val_mae: 0.5994\n",
      "Epoch 46/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6601 - mae: 0.5575 - val_loss: 0.9649 - val_mae: 0.7619\n",
      "Epoch 47/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6599 - mae: 0.5739 - val_loss: 0.6127 - val_mae: 0.5282\n",
      "Epoch 48/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5860 - mae: 0.5212 - val_loss: 0.6039 - val_mae: 0.5169\n",
      "Epoch 49/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6066 - mae: 0.5448 - val_loss: 0.6073 - val_mae: 0.5255\n",
      "Epoch 50/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6196 - mae: 0.5490 - val_loss: 0.5678 - val_mae: 0.5195\n",
      "Epoch 51/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6071 - mae: 0.5419 - val_loss: 0.5818 - val_mae: 0.5194\n",
      "Epoch 52/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5808 - mae: 0.5393 - val_loss: 0.6121 - val_mae: 0.5400\n",
      "Epoch 53/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6045 - mae: 0.5367 - val_loss: 0.5984 - val_mae: 0.5275\n",
      "Epoch 54/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6270 - mae: 0.5536 - val_loss: 0.5934 - val_mae: 0.5180\n",
      "Epoch 55/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5645 - mae: 0.5111 - val_loss: 0.5856 - val_mae: 0.5326\n",
      "Epoch 56/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5430 - mae: 0.5068 - val_loss: 0.7304 - val_mae: 0.6196\n",
      "Epoch 57/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5780 - mae: 0.5323 - val_loss: 0.6269 - val_mae: 0.5462\n",
      "Epoch 58/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5767 - mae: 0.5283 - val_loss: 0.6537 - val_mae: 0.5700\n",
      "Epoch 59/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5320 - mae: 0.5064 - val_loss: 0.5351 - val_mae: 0.5014\n",
      "Epoch 60/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5699 - mae: 0.5233 - val_loss: 0.5739 - val_mae: 0.5163\n",
      "Epoch 61/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5165 - mae: 0.5004 - val_loss: 0.5609 - val_mae: 0.5082\n",
      "Epoch 62/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5227 - mae: 0.5060 - val_loss: 0.5705 - val_mae: 0.5197\n",
      "Epoch 63/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5328 - mae: 0.5105 - val_loss: 0.5571 - val_mae: 0.5138\n",
      "Epoch 64/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4912 - mae: 0.4732 - val_loss: 0.6395 - val_mae: 0.5632\n",
      "Epoch 65/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5546 - mae: 0.5177 - val_loss: 0.6476 - val_mae: 0.5530\n",
      "Epoch 66/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.4729 - mae: 0.4630 - val_loss: 0.5621 - val_mae: 0.5143\n",
      "Epoch 67/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4992 - mae: 0.4863 - val_loss: 0.6015 - val_mae: 0.5463\n",
      "Epoch 68/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5308 - mae: 0.5097 - val_loss: 0.5649 - val_mae: 0.5150\n",
      "Epoch 69/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4971 - mae: 0.4901 - val_loss: 0.5532 - val_mae: 0.5138\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "normalize = layers.Normalization()\n",
    "normalize.adapt(features_train)\n",
    "model = keras.Sequential([\n",
    " normalize,   \n",
    " layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"),\n",
    " layers.Dropout(0.2),\n",
    " layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"),\n",
    " layers.Dropout(0.2),\n",
    " layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"),\n",
    " layers.Dropout(0.2),\n",
    " layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"),\n",
    " layers.Dropout(0.2),\n",
    " layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"),\n",
    " layers.Dense(1)\n",
    " ])\n",
    "'''\n",
    "normalize = layers.Normalization()\n",
    "normalize.adapt(features_train)\n",
    "model = keras.Sequential([\n",
    "     normalize,\n",
    "    layers.Dense(128,kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=[11]),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32,kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "   # layers.Dropout(0.2),\n",
    "   # layers.Dense(64,kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "#model.compile(loss = tf.keras.losses.MeanSquaredError(), optimizer = tf.keras.optimizers.Adam())\n",
    "#scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "#model.compile(optimizer='adam',loss='mae',)\n",
    "features_val=features_train[:200]\n",
    "partial_features_train=features_train[200:]\n",
    "labels_val=labels_train[:200]\n",
    "partial_labels_train=labels_train[200:]\n",
    "es = EarlyStopping(monitor='val_loss',patience=10, mode='min',start_from_epoch=50,restore_best_weights=True)\n",
    "#partial_features_train=scaler.fit_transform(partial_features_train)\n",
    "#features_val=scaler.transform(features_val)\n",
    "initial_weights = model.get_weights()\n",
    "history=model.fit(partial_features_train, partial_labels_train, epochs=100,validation_data=(features_val,labels_val),callbacks=[es])\n",
    "\n",
    "#history = model.fit( partial_features_train, partial_labels_train, validation_data=(features_val, labels_val), #batch_size=256, epochs=100,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [array([ 8.32369   ,  0.530559  ,  0.27247068,  2.555473  ,  0.088448  ,\n",
      "       15.876075  , 46.657154  ,  0.99677396,  3.3116498 ,  0.66002345,\n",
      "       10.4181    ], dtype=float32), array([2.9706898e+00, 3.2114483e-02, 3.8169973e-02, 2.0598800e+00,\n",
      "       2.4317845e-03, 1.0628546e+02, 1.0843245e+03, 3.4418256e-06,\n",
      "       2.3702282e-02, 3.0462939e-02, 1.1072987e+00], dtype=float32), 0]\n",
      "Final weights: [array([ 8.32369   ,  0.530559  ,  0.27247068,  2.555473  ,  0.088448  ,\n",
      "       15.876075  , 46.657154  ,  0.99677396,  3.3116498 ,  0.66002345,\n",
      "       10.4181    ], dtype=float32), array([2.9706898e+00, 3.2114483e-02, 3.8169973e-02, 2.0598800e+00,\n",
      "       2.4317845e-03, 1.0628546e+02, 1.0843245e+03, 3.4418256e-06,\n",
      "       2.3702282e-02, 3.0462939e-02, 1.1072987e+00], dtype=float32), 0, array([[ 0.02143197,  0.05318467, -0.01571003, ...,  0.07901916,\n",
      "         0.02074603,  0.06733321],\n",
      "       [-0.09447554,  0.00370453,  0.02725834, ...,  0.03778074,\n",
      "        -0.03718758,  0.06012679],\n",
      "       [-0.0452315 , -0.08417207,  0.077671  , ...,  0.06974353,\n",
      "         0.01978246,  0.1211962 ],\n",
      "       ...,\n",
      "       [ 0.09271393,  0.074062  ,  0.01845881, ...,  0.0373348 ,\n",
      "        -0.00818752, -0.05260668],\n",
      "       [-0.15701436, -0.01610846,  0.09570843, ..., -0.10610771,\n",
      "         0.04438837,  0.01138077],\n",
      "       [-0.07561114, -0.01101903,  0.09533066, ..., -0.12775442,\n",
      "         0.01664237,  0.07306797]], dtype=float32), array([-1.23512246e-01,  3.42276730e-02, -2.54878728e-03,  3.80203798e-02,\n",
      "       -1.69619858e-01,  3.34763937e-02,  1.00107558e-01, -1.30485952e-01,\n",
      "        6.74145445e-02,  3.56583297e-02, -8.26861709e-02,  6.81492984e-02,\n",
      "        4.96392772e-02, -3.28427479e-02,  1.51043367e-02, -1.88557580e-02,\n",
      "        4.36587855e-02, -9.27628856e-03, -1.38646126e-01,  3.95402052e-02,\n",
      "       -6.53742254e-02,  4.47032452e-02,  2.70137936e-02,  5.59083000e-02,\n",
      "       -1.11090012e-01,  6.50590472e-03, -2.39792485e-02, -5.81148826e-02,\n",
      "        1.81234311e-02, -3.02814469e-02,  9.00206044e-02,  8.15537721e-02,\n",
      "        4.98424619e-02, -1.24512315e-01, -1.00074627e-01,  8.34753141e-02,\n",
      "       -2.41862684e-02,  9.13806409e-02,  7.79651105e-02,  2.23380793e-02,\n",
      "       -1.38856284e-02, -4.33404855e-02, -1.56777024e-01, -1.09973907e-01,\n",
      "       -1.18292607e-02, -1.98842660e-01, -4.08394784e-02, -2.27654725e-02,\n",
      "       -1.36447385e-01,  3.90206650e-02,  1.14189517e-02,  4.91102878e-03,\n",
      "       -1.68397697e-03, -1.41185641e-01,  1.03107415e-01,  8.03332701e-02,\n",
      "       -3.33496812e-03, -8.64495635e-02, -1.06778994e-01, -8.66286457e-02,\n",
      "        2.39491668e-02, -1.80989072e-01, -6.27621636e-02,  1.18032908e-02,\n",
      "       -2.05074809e-02,  5.21510839e-02, -1.36678234e-01, -1.34559065e-01,\n",
      "       -1.19388020e-02, -5.91372047e-03, -2.31065173e-02,  1.48044815e-02,\n",
      "       -9.23729092e-02, -2.05425695e-02, -1.14429511e-01, -8.08573589e-02,\n",
      "       -4.46579121e-02,  6.17669243e-03,  8.62487778e-03, -9.39208120e-02,\n",
      "        2.61831451e-02,  2.98109856e-02, -5.75576350e-02,  2.81065106e-02,\n",
      "        1.83581077e-02, -1.24922141e-01, -1.32311821e-01, -4.20680046e-02,\n",
      "       -9.91911665e-02, -2.87978649e-02, -1.04751170e-01, -1.59964543e-02,\n",
      "        7.25066289e-02, -1.26395032e-01,  5.85676804e-02,  7.83665776e-02,\n",
      "        1.88650005e-02, -1.30484343e-01,  2.51247138e-02, -4.56687436e-02,\n",
      "        9.19704735e-02,  4.92826030e-02, -1.73861340e-01, -1.56415850e-01,\n",
      "        4.47331145e-02, -4.86631505e-02, -3.30957845e-02,  6.31201938e-02,\n",
      "       -1.09615281e-01, -7.13455454e-02,  6.22909106e-02,  2.06465106e-02,\n",
      "       -1.85211971e-02,  3.90018597e-02, -5.19876592e-02, -1.48687428e-02,\n",
      "        2.00015772e-02,  7.76698440e-02,  6.29265234e-02, -3.46605200e-03,\n",
      "        5.00700139e-02, -9.39402655e-02, -8.17115083e-02,  6.34091049e-02,\n",
      "        4.73216809e-02,  2.15812251e-02,  2.58822385e-02,  1.75360329e-02,\n",
      "        4.13958728e-02,  8.68127495e-02,  4.78676893e-02,  9.44149569e-02,\n",
      "        7.96602592e-02,  6.68582246e-02,  4.15365957e-02,  7.54561275e-02,\n",
      "        6.65786341e-02,  4.29400355e-02,  4.25822148e-03, -1.57208145e-02,\n",
      "        7.08679156e-03, -6.36077300e-02,  5.94220944e-02,  3.09914220e-02,\n",
      "        8.16699490e-02, -3.12212892e-02,  5.61544821e-02, -1.68851856e-02,\n",
      "        4.89016436e-02, -8.79346430e-02, -2.14010430e-03,  8.13408569e-02,\n",
      "       -6.30558059e-02,  5.48748076e-02,  7.19335070e-03, -1.09306790e-01,\n",
      "        5.78363687e-02,  3.21501270e-02, -7.48276785e-02,  3.62033513e-03,\n",
      "       -3.58313173e-02,  4.48635742e-02, -3.21176425e-02,  5.96362539e-02,\n",
      "       -2.94948015e-02,  2.21133772e-02, -7.78410435e-02, -8.30444023e-02,\n",
      "       -1.25994280e-01,  7.59809911e-02, -7.71333724e-02,  6.30043894e-02,\n",
      "       -3.76079530e-02,  1.32338917e-02, -5.23988483e-03,  3.05260811e-03,\n",
      "        4.21043560e-02, -1.02226287e-01,  3.91987376e-02, -6.70914799e-02,\n",
      "        3.50069106e-02, -1.14890099e-01,  4.95514050e-02, -1.93441268e-02,\n",
      "       -1.04186036e-01,  4.62589599e-02,  2.90298034e-02,  6.76949397e-02,\n",
      "       -2.13015056e-03,  2.05380470e-02, -9.24441367e-02,  8.43106210e-02,\n",
      "        4.39252751e-03, -8.39555934e-02, -2.97358185e-02,  1.16442665e-01,\n",
      "        7.54880086e-02, -1.42215686e-02,  6.80590123e-02,  9.55989361e-02,\n",
      "        4.78408709e-02, -8.61104727e-02,  1.75456349e-02,  1.33860838e-02,\n",
      "        4.60033417e-02,  2.74544433e-02, -6.73596337e-02,  5.85151389e-02,\n",
      "        3.50205749e-02, -4.67036245e-03, -1.07770607e-01,  7.62053505e-02,\n",
      "       -6.91105099e-03,  6.81269467e-02, -8.61183926e-02, -1.21382639e-01,\n",
      "       -9.85471606e-02,  1.00122094e-01,  2.56931949e-02,  1.39978956e-02,\n",
      "       -1.33518875e-01, -1.06691346e-01,  1.90194920e-02,  6.95330799e-02,\n",
      "       -1.63922198e-02,  8.94103646e-02,  5.71058057e-02, -4.21892926e-02,\n",
      "       -1.00240991e-01,  1.93353873e-02,  3.47442292e-02,  3.15803997e-02,\n",
      "       -3.57139483e-02, -1.40822396e-01, -7.54875913e-02,  9.09670815e-02,\n",
      "       -7.73560032e-02, -2.07584165e-02,  4.71055657e-02,  6.75695688e-02,\n",
      "        3.26123759e-02, -1.12983147e-02,  7.86652789e-02,  8.57229531e-03,\n",
      "       -1.55007049e-01,  7.10232765e-04,  8.03030431e-02,  5.68978190e-02,\n",
      "        8.44160989e-02,  1.48350722e-04, -7.94026479e-02,  6.40563071e-02,\n",
      "       -9.77340862e-02, -1.50889978e-01, -7.69592598e-02,  7.25148916e-02],\n",
      "      dtype=float32), array([[ 3.9880810e-04, -3.7919679e-07,  8.1234844e-03, ...,\n",
      "        -4.3847060e-04,  1.1356118e-02,  5.7752612e-03],\n",
      "       [-7.6882876e-05,  1.4698138e-07, -6.2053394e-02, ...,\n",
      "        -2.8304596e-04,  7.6596841e-02, -1.0509059e-02],\n",
      "       [-2.9585809e-03, -7.4416749e-07, -3.2420721e-02, ...,\n",
      "        -2.4634073e-04, -1.1585163e-01, -1.2838619e-02],\n",
      "       ...,\n",
      "       [-1.3428018e-03, -3.6802194e-07, -2.1501267e-02, ...,\n",
      "        -3.2838292e-05, -6.8106227e-02,  7.4434867e-03],\n",
      "       [ 1.1937075e-03, -6.7237045e-07,  1.4286307e-02, ...,\n",
      "        -2.1050853e-05,  5.3625353e-02, -1.1618287e-02],\n",
      "       [-6.9578638e-04, -2.8003035e-07,  1.0139582e-02, ...,\n",
      "        -4.9802271e-04,  7.5274758e-02,  4.1136793e-03]], dtype=float32), array([-0.08376708, -0.03337552,  0.10253081,  0.14166288,  0.1523677 ,\n",
      "        0.1349871 , -0.02206873,  0.12365586,  0.15198183,  0.13853978,\n",
      "        0.02754701, -0.05763877, -0.04974315,  0.1165989 , -0.03107588,\n",
      "        0.13696462, -0.0381355 , -0.0406374 ,  0.14720328,  0.13487989,\n",
      "        0.12258977,  0.15923071,  0.06476264,  0.14839406, -0.04499661,\n",
      "        0.1086577 ,  0.13823462, -0.00942028,  0.12877199, -0.04219063,\n",
      "        0.01496015,  0.1427728 ,  0.14378956,  0.07792763,  0.13670331,\n",
      "        0.13610555,  0.1187059 , -0.04343035,  0.15796843,  0.10572261,\n",
      "        0.12831602,  0.09182128,  0.14921345,  0.00056731,  0.14780055,\n",
      "       -0.06972574,  0.13339809, -0.00830471, -0.07069203,  0.15797393,\n",
      "        0.10348479, -0.0826833 , -0.05921001,  0.13670762,  0.14080033,\n",
      "        0.1455714 ,  0.10519322, -0.11547844,  0.11358336,  0.13572568,\n",
      "       -0.06946398,  0.13426256, -0.02631462,  0.15457414,  0.11660647,\n",
      "        0.0139214 ,  0.13984568,  0.13688645,  0.15044674,  0.13381223,\n",
      "        0.13073836,  0.14499345,  0.1489452 ,  0.11451912,  0.13435104,\n",
      "       -0.0227346 ,  0.04563342,  0.14926097,  0.14727283,  0.1566408 ,\n",
      "        0.12410598,  0.1521365 ,  0.13435909,  0.14300723, -0.03101324,\n",
      "        0.14337404,  0.12479634,  0.09396914,  0.1331354 ,  0.1533121 ,\n",
      "       -0.02506636,  0.12463591,  0.1312746 ,  0.13721223,  0.13161495,\n",
      "        0.13738453,  0.14914653, -0.02431108,  0.13997157, -0.06199221,\n",
      "       -0.0628098 ,  0.14581618,  0.15443523,  0.13192117, -0.01115724,\n",
      "        0.13900319,  0.04269603, -0.04712066,  0.13128306, -0.07275084,\n",
      "       -0.07717838,  0.11064796,  0.11411428, -0.01948689,  0.12705612,\n",
      "        0.1682336 ,  0.02506648,  0.13526094, -0.04238855,  0.15214847,\n",
      "        0.11801985,  0.06661057, -0.04280027, -0.05096684,  0.05758534,\n",
      "        0.00271767,  0.14875722, -0.01296313], dtype=float32), array([[-4.72414795e-05, -1.07542121e-06, -1.88291640e-04, ...,\n",
      "        -1.21029373e-03, -1.97586417e-03, -3.55322190e-05],\n",
      "       [-2.85461880e-07,  1.78660670e-07, -2.29097182e-07, ...,\n",
      "        -7.41794395e-07,  8.86486077e-07, -1.06850386e-07],\n",
      "       [ 6.63070902e-02,  9.18146895e-07, -7.19448477e-02, ...,\n",
      "         2.13839952e-02,  1.35019079e-01, -2.87111886e-02],\n",
      "       ...,\n",
      "       [ 1.88898528e-04, -4.56796556e-07,  8.09531703e-05, ...,\n",
      "         4.68755279e-05, -1.56203518e-04,  9.07838839e-05],\n",
      "       [-1.70880102e-03, -8.44805243e-07, -1.28998339e-01, ...,\n",
      "         5.69281131e-02,  1.25897974e-01,  2.98406500e-02],\n",
      "       [ 1.41560994e-02, -1.09688858e-06,  2.46482678e-02, ...,\n",
      "         1.41947176e-02,  1.02424426e-02,  8.12439807e-03]], dtype=float32), array([ 0.25701743, -0.03349213,  0.2627286 ,  0.25477493,  0.16266917,\n",
      "       -0.1270677 ,  0.26044655,  0.25612047,  0.24272944,  0.23968254,\n",
      "        0.25936165,  0.25951537,  0.2610933 , -0.03826538, -0.02157502,\n",
      "       -0.0246688 ,  0.25674435,  0.27459234,  0.25670096, -0.05573466,\n",
      "        0.26667216,  0.24759167, -0.02500243,  0.2602394 ,  0.26113242,\n",
      "        0.2418399 ,  0.27275044, -0.03042494,  0.26895097,  0.26363713,\n",
      "        0.24614716,  0.27470654,  0.28195977,  0.27152097,  0.24668361,\n",
      "        0.23337261,  0.29507768, -0.03192589,  0.2494196 ,  0.23327321,\n",
      "       -0.01463191,  0.23421288,  0.26085645,  0.2607955 ,  0.25877267,\n",
      "        0.2768327 ,  0.2673022 ,  0.27575347,  0.23379888,  0.28225234,\n",
      "        0.23135343, -0.09240849, -0.05030534,  0.26818204,  0.16731845,\n",
      "       -0.03194533,  0.26351893,  0.17302932, -0.02296483,  0.27467328,\n",
      "        0.25450003,  0.15301551,  0.28050327,  0.27941635], dtype=float32), array([[ 5.3613638e-07,  8.8285805e-07, -2.7184486e-02, ...,\n",
      "        -9.5352207e-06, -1.3324500e-06, -2.1407604e-06],\n",
      "       [ 7.1520581e-08, -4.9420601e-07, -1.6252485e-06, ...,\n",
      "        -8.3352791e-07, -1.0254031e-06,  1.5109201e-06],\n",
      "       [-3.2582566e-06,  3.7912224e-07, -1.7715935e-01, ...,\n",
      "         5.0622389e-06, -4.6644854e-07, -1.2940245e-06],\n",
      "       ...,\n",
      "       [-6.6721162e-07,  2.3386163e-07,  2.2531740e-02, ...,\n",
      "        -8.0868795e-06, -1.8021327e-06, -1.0388164e-06],\n",
      "       [-4.6097425e-06, -3.5623486e-06,  2.3663095e-01, ...,\n",
      "        -1.1677867e-05,  1.6121083e-06, -2.6702730e-07],\n",
      "       [ 1.2926728e-06, -1.8185790e-06,  7.2851188e-02, ...,\n",
      "         8.0726975e-05,  6.2868281e-08, -6.0610514e-06]], dtype=float32), array([-0.05516299, -0.05686539,  0.42828563,  0.42479476,  0.42933542,\n",
      "        0.43044218,  0.39691588, -0.06064485, -0.36757112,  0.42345086,\n",
      "        0.43396348,  0.3244456 , -0.06190596, -0.06318077,  0.4248045 ,\n",
      "        0.42582026, -0.06017756, -0.06114615,  0.43368945,  0.42695522,\n",
      "       -0.05422755, -0.03999925,  0.2590113 , -0.05643343,  0.43745923,\n",
      "       -0.01977952, -0.04084356, -0.03898009,  0.3996335 , -0.05419455,\n",
      "       -0.06347091, -0.06102175], dtype=float32), array([[-0.04727571],\n",
      "       [-0.01372359],\n",
      "       [ 0.32359883],\n",
      "       [ 0.10696056],\n",
      "       [ 0.37369156],\n",
      "       [ 0.3223549 ],\n",
      "       [ 0.20653385],\n",
      "       [-0.3049681 ],\n",
      "       [-0.07514624],\n",
      "       [ 0.09401909],\n",
      "       [ 0.18887836],\n",
      "       [ 0.22833484],\n",
      "       [-0.14612718],\n",
      "       [-0.01325627],\n",
      "       [ 0.10874966],\n",
      "       [ 0.08627246],\n",
      "       [-0.06029712],\n",
      "       [-0.04248889],\n",
      "       [ 0.47431633],\n",
      "       [ 0.1778303 ],\n",
      "       [-0.2661984 ],\n",
      "       [-0.08049199],\n",
      "       [ 0.19992247],\n",
      "       [-0.18678343],\n",
      "       [ 0.48639852],\n",
      "       [-0.33231655],\n",
      "       [-0.14845224],\n",
      "       [-0.06939359],\n",
      "       [ 0.32523736],\n",
      "       [-0.26421353],\n",
      "       [-0.01489547],\n",
      "       [-0.16881642]], dtype=float32), array([0.4281123], dtype=float32)]\n",
      "Weights have been updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niccolo/python-projects/optimization/env/lib/python3.10/site-packages/numpy/core/numeric.py:2457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a1, a2 = asarray(a1), asarray(a2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial weights:\", initial_weights)\n",
    "final_weights = model.get_weights()\n",
    "print(\"Final weights:\", final_weights)\n",
    "\n",
    "# Check if the weights have changed\n",
    "if np.array_equal(initial_weights, final_weights):\n",
    "    print(\"Weights are not being updated.\")\n",
    "else:\n",
    "    print(\"Weights have been updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss= history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "plt.plot(range(1, len(loss) + 1), loss,'bo',label=\"Training loss\")\n",
    "plt.plot(range(1, len(loss) + 1), val_loss,'b',label=\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results : [0.4894619584083557, 0.48604923486709595]\n"
     ]
    }
   ],
   "source": [
    "results=model.evaluate(features_test, labels_test, verbose=0)\n",
    "print(\"Test results : {results}\".format(results=results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "MSE: 0.4205\n",
      "RMSE: 0.6484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = model.predict(features_val)\n",
    "predictions[0]\n",
    "predictions[1]\n",
    "\n",
    "mse= mean_squared_error(labels_val,predictions)\n",
    "\n",
    "\n",
    "print(\"MSE: %0.4f\" % (mse))\n",
    "rmse= np.sqrt(mse)\n",
    "print(\"RMSE: %0.4f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val=np.array(labels_val)\n",
    "labels_val[0]\n",
    "labels_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niccolo/python-projects/optimization/env/lib/python3.10/site-packages/pygad/pygad.py:1139: UserWarning: The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\n",
      "  warnings.warn(\"The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  [[6.947922]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[7.320034]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[5.8669624]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "output:  [[13.965031]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "output:  [[17.304375]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[8.77989]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[17.321186]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[5.1929984]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[12.663376]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "output:  [[6.3488593]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "output:  [[13.985014]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[8.690211]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "output:  [[7.943979]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[7.543854]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[14.028918]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[8.79161]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[7.808987]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "output:  [[8.128996]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[8.939046]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[8.755748]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[7.3549304]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[7.9361653]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[8.85314]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[8.850632]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "output:  [[8.73295]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "output:  [[9.24534]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "output:  [[8.826929]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "output:  [[8.956403]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "output:  [[8.735239]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[12.266173]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "output:  [[15.251331]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "output:  [[9.59906]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "output:  [[9.634859]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "output:  [[8.765538]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "output:  [[9.212896]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "output:  [[8.919589]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.563472]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.30217]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "output:  [[14.850241]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "output:  [[9.916898]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "output:  [[9.42502]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "output:  [[9.196104]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "output:  [[9.02696]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[9.070583]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[9.622368]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "output:  [[9.525609]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "output:  [[9.654557]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[9.500603]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[9.206392]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "output:  [[9.43296]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[9.979511]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "output:  [[9.6138935]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "output:  [[7.919881]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "output:  [[9.62923]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[17.648014]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.568458]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.512561]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[10.216079]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[14.007092]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[14.199889]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.794293]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.942247]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.791968]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.536096]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.321487]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.973814]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[16.680876]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[8.205068]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.988367]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[9.977525]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "output:  [[9.197743]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.993313]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.805496]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[9.92709]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.658632]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[9.886505]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "output:  [[9.91844]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "output:  [[10.04759]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "output:  [[9.959782]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[10.021049]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "output:  [[10.0478325]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "output:  [[13.305762]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "output:  [[9.87948]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "output:  [[11.720628]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "output:  [[9.924581]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.788498]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.960429]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[9.771768]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "output:  [[9.9686365]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "output:  [[9.901563]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[9.9583435]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[10.26318]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "output:  [[9.968946]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "output:  [[10.010614]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "output:  [[11.994753]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.966921]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "output:  [[9.839886]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "output:  [[10.167798]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "output:  [[9.837122]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.187521]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[10.013592]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[10.246567]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.975299]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[10.2213955]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[10.005029]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.737005]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[10.077275]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.426057]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[10.083888]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.978706]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.971811]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.951417]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[9.992056]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "output:  [[9.9326935]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[10.014596]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.889744]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[10.237804]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[9.971709]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[10.045746]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[9.867883]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.684634]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[9.986468]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.723999]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "output:  [[9.954035]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.904309]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.823798]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.961684]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.45372]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[7.327191]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.79204]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.586067]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.701784]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.648252]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.966206]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.844432]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.41426]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.834952]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.8040085]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "output:  [[6.1563]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "output:  [[9.62843]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "output:  [[9.638323]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[9.787882]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "output:  [[9.939728]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.675756]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "output:  [[9.825852]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "output:  [[9.844649]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[9.9207115]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[9.39239]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.966873]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[10.082701]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.6209755]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[10.834575]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[9.308975]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[9.776716]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[9.296263]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[10.034496]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[6.246864]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.864432]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[10.042905]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[9.557766]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[9.895534]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[10.047815]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[10.073032]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[9.799529]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[10.157587]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.844552]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[17.074095]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.904635]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.860755]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "output:  [[9.872607]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "output:  [[6.0983872]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "output:  [[9.966685]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "output:  [[9.818018]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[10.053644]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[9.562885]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "output:  [[10.075837]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "output:  [[9.965674]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[10.140228]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "output:  [[10.019407]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[10.087076]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.935246]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.658876]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[10.075334]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "output:  [[9.630616]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.629609]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[10.479708]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.954619]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.221339]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[10.020224]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[10.037209]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[10.086302]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "output:  [[9.224636]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[10.046459]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[10.098513]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[9.996219]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.647873]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[10.098243]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[10.064348]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[15.446302]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.286419]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "output:  [[9.975826]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[9.873313]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[9.949515]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[10.232258]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "output:  [[9.3258505]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[10.101773]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[9.852665]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[10.146349]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "output:  [[9.555188]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[10.129061]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.819647]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[9.813397]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "output:  [[10.001482]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[10.032644]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[10.276066]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[6.1735144]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[10.152984]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.531968]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[9.493941]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[17.027046]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.842081]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.751576]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[10.005364]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "output:  [[9.650602]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.415834]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[9.902391]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.58148]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.058067]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.715706]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[9.563406]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[10.016978]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.833835]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[10.078427]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[10.013684]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[9.836776]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.881322]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.998918]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "output:  [[10.482816]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "output:  [[9.893314]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[9.964173]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.950332]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[9.7417145]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[10.070492]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "output:  [[10.002164]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[16.30792]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "output:  [[9.571433]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.762353]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.678903]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[8.176111]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.810964]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[9.764942]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.514879]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[10.012943]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[10.003529]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.590981]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.145047]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[9.436918]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[9.981182]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[10.026482]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.832231]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[10.003071]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.7585745]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.679723]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[9.909403]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.941179]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[10.028151]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[9.9691725]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[9.940854]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "output:  [[9.885863]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.978543]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[9.505523]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[10.008988]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[10.134353]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[10.378486]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "output:  [[9.9721575]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.319631]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[10.134433]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[9.952857]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[10.017055]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[14.367142]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[10.291632]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.227618]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "output:  [[9.996411]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "output:  [[9.720209]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.939671]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[9.460497]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[10.061759]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[10.180979]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[7.0643606]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[10.018726]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.802257]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "output:  [[9.998274]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.471781]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.64686]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[10.30933]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[9.975808]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "output:  [[10.001078]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[9.724296]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[10.010094]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[10.488093]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[10.0806675]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.782573]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "output:  [[9.948367]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "output:  [[18.001083]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.986388]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[17.491194]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[10.087983]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[10.093417]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.878934]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[10.13447]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[10.330069]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[8.821671]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.7382]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[10.188947]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[10.198125]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[10.076645]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[10.026264]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[10.111526]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "output:  [[10.053474]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[10.3288965]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.983171]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[10.342553]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[10.373205]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[9.680671]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "output:  [[9.7881155]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[10.0524645]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "output:  [[9.970716]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[10.004317]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.728234]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.929949]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[10.006431]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.711952]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.924844]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.9837055]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.940624]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "output:  [[9.97447]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "output:  [[9.874492]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[10.006775]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.729356]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.884399]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[9.6520815]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "output:  [[10.035985]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.997339]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[9.981045]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "output:  [[9.990934]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[9.720046]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[7.254952]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[10.064509]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[10.051256]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "output:  [[10.023432]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "output:  [[9.953156]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "output:  [[10.04421]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "output:  [[9.870155]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "output:  [[10.038642]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "output:  [[9.947553]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[10.031093]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "output:  [[10.176363]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "output:  [[10.01107]]\n"
     ]
    }
   ],
   "source": [
    "import pygad\n",
    "\n",
    "desidered_output=10\n",
    "def fitness_func(ga_instance,solution,solution_idx):\n",
    "    input_array=np.array(solution)\n",
    "    input_array_for_prediction = np.expand_dims(input_array,axis=0)\n",
    "    output= model.predict(input_array_for_prediction)\n",
    "    print(\"output: \",output)\n",
    "    fitness = 1.0 / np.abs(output - desidered_output)\n",
    "    return fitness\n",
    "\n",
    "#sol_per_pop=100\n",
    "#num_generations=1000\n",
    "#num_genes=len(features_train)\n",
    "#num_parents_mating=5\n",
    "\n",
    "num_generations = 50\n",
    "num_parents_mating = 4\n",
    "\n",
    "sol_per_pop = 8\n",
    "num_genes = 11\n",
    "\n",
    "init_range_low = -1\n",
    "init_range_high = 10\n",
    "\n",
    "gene_space = [np.arange(4.0, 15.0, 0.1),np.arange(0, 0.9, 0.01),np.arange(0, 1, 0.01),\n",
    "              np.arange(0, 18.0, 0.1),np.arange(0.05, 0.5, 0.001),\n",
    "              np.arange(2, 60, 1),np.arange(6, 160, 1),np.arange(0.800, 1.100, 0.001),np.arange(2.8, 4.0, 0.1),\n",
    "              np.arange(0.10, 2.00, 0.01),np.arange(8.0, 15.0, 0.1)]\n",
    "\n",
    "parent_selection_type = \"sss\"\n",
    "keep_parents = 1\n",
    "\n",
    "crossover_type = \"single_point\"\n",
    "\n",
    "mutation_type = \"random\"\n",
    "mutation_percent_genes = 10\n",
    "\n",
    "#ga_instance=pygad.GA(num_generations=num_generations,sol_per_pop=sol_per_pop,fitness_func=fitness_func,num_genes=num_genes,num_parents_mating=num_parents_mating,m#utation_type=None)\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=fitness_func,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       num_genes=num_genes,\n",
    "                       gene_space=gene_space,\n",
    "                       #init_range_low=init_range_low,\n",
    "                       #init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_percent_genes=mutation_percent_genes)\n",
    "\n",
    "ga_instance.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "output:  [[10.04421]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "output:  [[9.870155]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "output:  [[9.947553]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "output:  [[10.176363]]\n",
      "Parameters of the best solution : [1.38e+01 2.00e-01 1.10e-01 4.10e+00 2.65e-01 2.20e+01 1.32e+02 9.27e-01\n",
      " 3.10e+00 1.77e+00 1.47e+01]\n",
      "Fitness value of the best solution = [[927.94336]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Predicted output based on the best solution : [[10.001078]]\n"
     ]
    }
   ],
   "source": [
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
    "\n",
    "input_array=np.array(solution)\n",
    "input_array_for_prediction = np.expand_dims(input_array,axis=0)\n",
    "    \n",
    "prediction =  model.predict(input_array_for_prediction)\n",
    "print(\"Predicted output based on the best solution : {prediction}\".format(prediction=prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
